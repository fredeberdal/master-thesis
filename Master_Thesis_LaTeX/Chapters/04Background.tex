Code Reviews are an important component of modern software development. The current landscape of code reviews is diverse and multifaceted, reflecting the methodologies and tools that have spurred into existence. Initially introduced in as a rigorous inspection and critique of code, code reviews has evolved significantly. The underlying motivations of the thesis will now be explored through a literature review, to situate the study of code reviews in the wider context of academic research and industry practices.\\


\section{Code Review Definitions}
There are many definitions and various wordings for what Code Review and Peer Code Review are, and how they work. To ensure clarity and avoid misunderstandings, I have formulated a definition for PCR and CR based on my own understanding, as well as the research of Indriasari et al.~\cite{Indriasari_Luxton_2020} and Song et al.~\cite{Song_Goldstein_Sakr_2020}, covering the most essential aspects. \\

\noindent In this thesis, Code Review is defined as follows: 
\begin{quote}
    A Code Review is a systematic process in which software developers examine each other's code to identify bugs, improve code quality, and ensure compliance with coding standards. This practice is integral to maintaining the overall maintainability and security of software projects by identifying issues early, encouraging best practices, and facilitating knowledge sharing within the development team.
\end{quote}
And the definition for Peer Code Review:
\begin{quote}
    Peer Code Review is a structured activity in which students evaluate each other's code to provide feedback, identify errors, and suggest improvements. Unlike general code reviews in the industry, this practice focuses on enhancing the learning experience by developing students' critical thinking and coding skills, fostering collaborative learning, and preparing them for professional coding environments. 
\end{quote}


\section{Background}

A code review is a critical phase in the software development process that begins when a developer completes their task. During this phase, another developer or domain expert examines the code to identify logical errors, ensure that all specified requirements are met, check the adequacy of new and existing automated tests, and confirm adherence to style guidelines~\cite{atlassian_What_is_a_code_review, Expectations_outcomes, sadowski_google}.\\

Such reviews are seamlessly integrated into the existing workflow of the team, which is particularly beneficial in task branching environments. Reviews occur after coding and testing, but before the code is integrated into the main branch to protect against the integration of flawed code and to maintain overall code quality~\cite{atlassian_What_is_a_code_review}. For code that intersects multiple domains, the participation of multiple reviewers ensures a comprehensive evaluation, improving the detection of potential problems and strengthening the robustness of the software before its final merging into a central branch~\cite{gitlab_What_is_a_code_review?}. These reviews are crucial for detecting bugs, pinpointing logic discrepancies, and identifying special cases~\cite{Expectations_outcomes}. \\

Originating in the early stages of computer programming, the practice of code review has shifted from a stringent, formalized procedure to a more adaptive and central part of modern software development processes~\cite{Wang_evolution}. The next sections explore the historical development, transformation, and current dynamics of code reviews, emphasizing their importance within the software development cycle.

\subsection{Early Stages of Code Review}
Code reviews originated in the 1970s as a formal practice within the realm of software verification, profoundly shaped by the structured programming\footnote{Structured Programming is a programming paradigm that facilitates the creation of programs with readable code and reusable components.~\cite{What_is_Structured_Programming?}} and emerging software engineering principles of the time. The concept was notably advanced by Michael Fagan at IBM, who, in 1976, introduced a comprehensive inspection process as a key component of broader software quality assurance measures~\cite{sadowski_google, Fagan}. Fagan's approach was systematic, encompassing various phases such as planning, overview sessions, detailed preparation, the code inspection meeting itself, and subsequent follow-up actions.\\

The early stages of code review practices were primarily manual, where the focus was on collective in-person meetings for detailed, line-by-line analysis of code. These sessions aimed to detect defects, ensure that coding standards were followed, and improve the overall quality and maintainability of the software. Although effective in early defect detection, these methods were resource intensive and required considerable time and effort from the developers involved. This period laid the foundation for the code review process, highlighting the importance of thorough examination.


\section{Integration with Agile Methodologies}
Code reviews have evolved significantly from their inception to the current era. Originally referred to as "software inspections" and "walk-throughs," traditional code reviews were formal, rigorous, and time-intensive processes that focused primarily on quality assurance~\cite{Wang_evolution, Fagan}. With the rise of current development practices and methodologies, the dynamics of code reviews also changed significantly. The introduction of modern review tools like Gerrit\footnote{https://www.gerritcodereview.com/} and ReviewBoard\footnote{https://www.reviewboard.org/} has revolutionized the process. The process became more user-friendly and was incorporated into everyday workflows and the iterative cycles of agile methodologies, as asynchronous reviews enabled developers to evaluate code at their own convenience. \\

Platforms such as GitHub\footnote{https://github.com/} and GitLab\footnote{https://about.gitlab.com/} have further streamlined the process with the "pull request" feature, allowing developers to propose, discuss, and merge code changes efficiently. This system greatly supported asynchronous and distributed code reviews, enabling flexible and effective collaboration among teams spread across various locations. \\

The shift towards modern code review has not only increased the efficiency and effectiveness of the review process but also broadened its scope~\cite{Wang_evolution}. Furthermore, the availability of extensive datasets and more advanced analytical tools has facilitated more empirical studies and user research, which leads to a deeper understanding of the best practices and socio-technical aspects of code reviews~\cite{Agile_Code_Review}. Section \ref{modern} will delve into how modern code reviews go further than merely identifying bugs and defects.


\section{Modern State of Code Reviews} \label{modern}
In the current software development environment, code reviews are a critical component of the DevOps and CI/CD pipeline. Various automated tools simplified this process by providing static code analysis, automated testing, and continuous integration. These tools handle straightforward issues, allowing human reviewers to focus on the more complex aspects of the code such as design, integrity, architecture, and maintainability~\cite{Tabnine_2023}. \\

Modern code reviews have shifted from focusing only on identifying bugs to also include knowledge sharing, maintaining code quality, and fostering team collaboration. Bacchelli \& Bird explain that although bug detection remains a key motivation of reviews, the primary goals have expanded to also include mentoring and learning~\cite{Bacchelli_Bird_2013}. Experienced developers guide their peers and junior colleagues, ensuring a uniform understanding of the codebase across the team. This practice not only improves the quality of the code, but also promotes steady learning and collaboration. In open-source projects, the social aspect of code reviews has become increasingly notable, with discussions often occurring in public forums that contribute to engagement and a broader community learning experience.\\

The evolution of code reviews mirrors the broader transformations in software development practices. In transition from a formal structured activity to an integrated collaborative process, code reviews have adapted to the dynamic demands of modern software development. Today, they are an important element to ensure code quality and improve team collaboration within the evolving landscape of software engineering~\cite{Wang_evolution}. \\

A senior developer interviewed in Bacchelli \& Bird’s research~\cite{Bacchelli_Bird_2013} stated, "\textit{One of the things that should be happening with code reviews over time is a distribution of knowledge. If you do a code review and did not learn anything about the area and you still do not know anything about the area, then that was not as good a code review as it could have been.}” This highlights the evolving nature of code reviews as tools for both quality assurance and educational improvement.\\


\section{Challenges with Modern Code Reviews}

\subsection{Impact of Reviewer Fatigue on Quality}\label{Reviewer_Fatigue}
Bagirov et al.'s study~\cite{Bagirov_2023} highlights the importance of reviewing problematic files or files with significant changes first, as the quality of code reviews tends to diminish over time due to reviewer fatigue. They conducted research showing that files positioned later in the review process receive fewer comments, increasing the likelihood of missing defects and improvements. This result suggests that the cognitive load of the reviewers decreases as the review session lasts longer, which impacts their ability to thoroughly evaluate the files reviewed later in the project. To mitigate this effect, it is recommended to prioritize files with more extensive changes or known issues early in the review process. This or similar strategies could help maintain high review quality while also ensuring that critical areas receive the necessary attention they need~\cite{Bagirov_2023}. Further investigation of effective methods for selecting these critical files could provide additional insights. Methods such as considering file length, searching for specific keywords, identifying code smells, and measuring complexity levels could facilitate for more improvements in the review process. Different methods of selecting files are investigated in Chapter \ref{Methodology}. \\

The research by Bagirov et al.~\cite{Bagirov_2023} also compares different file-ordering strategies and their impact on review quality. They conclude that the '\textit{Code Diff}' ordering, which prioritizes files based on the number of lines changed since the last examination, significantly outperforms the traditional alphabetical ordering used by many code review tools such as GitHub and Gerrit. The code diff technique ensures that files with the most changes are reviewed first, so that the reviewers' peak attention can be utilized for these crucial areas, reducing the probability of critical defects being overlooked. \\
\newpage

Fregnan et al.~\cite{Fregnan_2022} explore how the position of files within a code review affects the likelihood of defect detection. Through an extensive analysis of GitHub pull requests and a controlled experiment with developers, they found that files appearing earlier in the review process receive more comments and are more likely to have defects identified. Despite 72.6\% of participants in the experiment believing that file position did not impact their ability to detect defects, the data showed a significant decrease in defect detection for the files positioned last. This highlights a cognitive bias where the reviewers' self-assessment does not align with their actual performance. In educational contexts, where reviewers are likely less experienced, this bias may be even more pronounced, suggesting a need for structured review processes that mitigate the effects of file positioning to improve overall defect detection rates~\cite{Fregnan_2022}. \\

As discovered by Bagirov et al. and Fregnan et al.~\cite{Bagirov_2023, Fregnan_2022}, file-ordering had a great impact on review activity and defect detection rates. Additional conclusions can be drawn from their research that the motivation of reviewers also decreases, along with the decreased detection of defects and reduced review activity. Therefore, techniques such as file-ordering can be particularly beneficial if used in an educational context, where it is especially important for students to be engaged and motivated~\cite{Indriasari_Luxton_2020}. In educational scenarios, focusing on the most critical files and excluding less relevant ones could be a viable strategy. In contrast, in industrial projects, a comprehensive review of all files is essential to ensure thorough bug detection and code quality before code is integrated into the codebase~\cite{Bagirov_2023}. \\


\subsection{Tool Limitations and Usability}
Bagirov et al.\cite{Bagirov_2023} highlight significant limitations in the tools used for code reviews. Popular platforms like GitHub and Gerrit typically sort files alphabetically, a method that does not account for measures like complexity or functionality of the code changes. This ordering can result in important files being reviewed less thoroughly if they appear later in the sequence, as discovered in the previous section. Improving tool design to incorporate file-ordering strategies based on different measures and code complexity could significantly improve review outcomes. In addition, there are always improvements that can be implemented for better user interfaces. These improvements help manage reviewers' cognitive load, which could assist in maintaining focus throughout the review process. These improvements could streamline the review process, making it more efficient and effective~\cite{Bagirov_2023}. \\

\subsection{Reviewer Expertise and Training}
Both Bagirov et al. and Fregnan et al.~\cite{Bagirov_2023, Fregnan_2022} imply that the effectiveness of code reviews heavily depends on the expertise and training of the reviewers. Less experienced reviewers often struggle to identify complex defects, especially as they become fatigued. This challenge is even more evident in educational contexts, where students who may lack the necessary depth in their knowledge conduct peer code reviews. Enhancing the training provided to reviewers, which could include detailed guidelines and best practices, may help bridge this gap. Pairing novice reviewers with more experienced developers can also improve review quality. This mentoring approach not only helps identify defects more accurately, but also facilitates the important knowledge transfer phase mentioned above, as well as skill development among team members~\cite{Bagirov_2023, Fregnan_2022}. \\


\section{Code Review in an Educational Context}

Knowledge transfer, team building, and bug detection are pivotal benefits of code reviews in the industry~\cite{Wang_evolution}. However, in educational contexts, the main objective of code review is to improve code quality and learning outcomes, develop industry relevant skills, and deepen students' understanding of coding principles through active participation and peer feedback. By integrating code reviews into educational programs, students gain practical experience, both in providing and receiving feedback on their peers' work, which is crucial for their professional development~\cite{Indriasari_Luxton_2020}. \\

Indriasari et al.~\cite{Indriasari_Luxton_2020} identify five key obstacles to the implementation of Peer Code Reviews in education: (1) lack of knowledge or ability, (2) low engagement, (3) poor quality of reviews, (4) ineffective administrative processes, and (5) impracticality of the review process. The following sections elaborate on these obstacles and potential solutions. \\


\subsection{Lack of Knowledge}
For many students, their initial experience with code review can be intimidating due to a lack of coding and code review skills. Indriasari et al.~\cite{Indriasari_Luxton_2020} report that students often feel unqualified to review code effectively. However, Peer Code Reviews can significantly improve the students' understanding of computing concepts~\cite{Brown_2019}. To improve the accuracy and variety of student code reviews, Song et al.~\cite{Song_Goldstein_Sakr_2020} suggest a "training phase" before the actual reviews, where students familiarize themselves with potential code review rubrics\footnote{A rubric is an evaluation tool consisting of a set of criteria, a fixed scale, and descriptors that distinguish the differences in the levels of the scale~\cite{McTighe_Frontier}} and address subjective evaluations by those individuals with limited expertise. \\

Several studies have proposed solutions to streamline the review process for reviewers. MacLeod et al.~\cite{MacLeod_2018} suggest creating a project-specific review checklist to clearly outline the main areas of focus. Additionally, Indriasari et al.~\cite{Indriasari_Luxton_2020} recommend that educators play an active role in guiding students by providing detailed instructions or giving examples of how to write useful and descriptive comments. Instructors are also advised to establish clear evaluation criteria or rubrics before allowing students to submit numerical feedback or ratings. \\

\subsection{Low Engagement}
Ada \& Majid~\cite{Ada_Majid_2022} emphasize the need to increase student motivation in the code review process through gamification techniques, such as earning badges or points. These strategies not only make the process more engaging, but also promote active participation and improves the learning experience. The effectiveness of peer reviews is closely related to the level of student engagement~\cite{Indriasari_Luxton_2020}, and gamification has been shown to improve both the quantity and quality of feedback provided. Making the review process feel meaningful and rewarding can be a factor in increasing engagement. If the review is perceived as providing low value, it results in low engagement~\cite{Berkling_Neubehler_2019}. \\

\subsection{Low Review Quality}
Factors such as lack of knowledge, effort, biases, and personal motives can lead to low review quality. To address these issues, researchers recommend various strategies to improve the reliability and objectiveness of peer reviews. Indriasari et al.~\cite{Indriasari_Luxton_2020} cite studies that show significant differences between scores given by the tutors and the students. Song et al.~\cite{Song_Goldstein_Sakr_2020} propose recognizing the potential inaccuracies in individual student reviews and suggest aggregating multiple reviews to compensate for these inaccuracies, resulting in a more accurate median result. Their findings indicate that the standard deviation of five student reviews is comparable to that of TA-based reviews, underscoring the value of collective assessments over individual evaluations.\\

Wang et al.~\cite{Wang_evolution} introduced a model of penalties and rewards to encourage objectiveness in reviews, rewarding students whose scores align closely with the mean of the group. This model highlights the benefits of structured approaches in improving the peer review process. Anonymity has also been shown to be effective in reducing biases and increasing participation~\cite{Indriasari_Luxton_2020, Ada_Majid_2022}. \\

\subsection{Ineffective Administration Processes}
In their research, Indriasari et al.~\cite{Indriasari_Luxton_2020} observed that implementing Peer Code Review can place a significant burden on educational staff due to the demanding workload. However, they also identified studies indicating that PCR can alleviate the administrative burden by reducing the extensive manual grading required~\cite{Hundhausen_Agrawal_Agarwal_2013}. A recurring issue was the need to compare staff and student reviews, highlighting the challenge of managing workload efficiently. \\

\subsection{Impractical Review Process} \label{Impractical_review_process}
Managing an effective code review process in educational contexts can be challenging, as you have to balance the number of reviews with the workload of the students. Song et al.~\cite{Song_Goldstein_Sakr_2020} highlight the importance of combining multiple reviews to make evaluations more accurate. However, they also point out that it is important to consider how much time students spend on Peer Code Review tasks to avoid overburdening them. Finding a balance between these is crucial to ensure that the PCR process does not negatively affect students' motivation and engagement at the expense of learning. \\

Overburdening students with too many reviews can lead to fatigue and reduced review quality. Indriasari et al.~\cite{Indriasari_Luxton_2020} therefore highlight that educators must manage the frequency and duration of code reviews to prevent the process from becoming excessively demanding. Sadowski et al.~\cite{sadowski_google} present an efficient model that was used at Google, where developers spend an average of 3.2 hours per week on reviews, compared to the average of 6.4 hours per week in open-source software projects. This could suggest that Google's review process is more manageable, indicating that similar methods adapted to educational contexts, where time often is a constraining factor, could be useful. However, this could also be biased, and an indication that Google has more experienced developers than the average open-source project. \\

Additionally, Song et al.~\cite{Song_Goldstein_Sakr_2020} discuss the importance of rubrics with clear guidelines for evaluating solutions as part of the review process. While creating detailed rubrics is time-intensive, it enhances the effectiveness and quality of reviews and allows the rubric to be reused in future terms. However, they point out that the design of the rubric is crucial to consider for a practical process, as extensive rubric texts and an overload of options can diminish review accuracy. Instead, Song et al. recommend using subjective statements rather than point deductions to improve accuracy and encourage more thoughtful feedback. \\

A practical solution to streamline the review process and manage the workload is to focus on reviewing a selection of crucial code files rather than the entire codebase. By doing this, educators can ensure that students continue to engage in meaningful review activities without being overwhelmed. Following this approach allows for in-depth examination and feedback on key aspects of the code while maintaining a manageable workload for students. Indriasari et al.~\cite{Indriasari_Luxton_2020} suggest that course instructors should prioritize the most significant parts of the code that are likely to have the highest impact on learning outcomes. \\


% \section{Code Complexity}
% Kanskje legge inn en seksjon om code complexity her før jeg ramser opp alle teknikkene for selektering. 
% https://medium.com/@himanshuganglani/clean-code-cognitive-complexity-by-sonarqube-659d49a6837d
% https://blog.codacy.com/code-complexity



\section{Code Selection in Peer Code Review}\label{code-selection-techniques}
In industrial settings, the code that is submitted for review usually consists of new and modified code segments, typically displayed as \textit{pull requests}. In educational contexts on the other hand, Peer Code Reviews often often require students to evaluate entire code submissions. This approach is intended to provide students with a comprehensive understanding of the coding practices and logic of their peers. However, this can be overwhelming, especially for beginners, resulting in reduced engagement, decreased learning outcomes, and lower review quality~\cite{Indriasari_Luxton_2020}. The code selection process during Peer Code Reviews plays a crucial role in the resulting effectiveness and efficiency of the review process. \\

Properly selecting which code segments to review can reduce student fatigue, thus maintaining their motivation, ensure that the review process is manageable, and improve the overall quality of feedback. It is therefore important to have other mechanisms for code selection in education compared to the industry. When students are not overwhelmed by the amount of code to review, they can concentrate on the quality of their analysis. Selecting crucial sections of the code, such as recently taught functions or complex logic, for review ensures that the students' reviews are both focused and meaningful~\cite{Indriasari_Luxton_2020, Song_Goldstein_Sakr_2020}.




\subsection{Selection Techniques}
The various techniques for selecting specific code segments that are crucial and relevant for review will be introduced in this section. The aim of these techniques is to identify important parts of the codebase that require closer examination, thereby improving the effectiveness of the peer review process. By employing various different selection methods and metrics, each technique offers a unique perspective on which code segments should be prioritized for review, and why. However, all the different selection techniques should ultimately contribute to improve the review process and student engagement if utilized properly. \\

\subsubsection{Size Selection}
The Size Selection technique is a method that involves analyzing all files in a project to identify those with the most lines of code, excluding empty lines and comment lines. This technique targets the largest files, which contain the most code and that are likely to contain significant functionality or complex logic. Focusing on these substantial parts of the codebase, this approach ensures that critical sections receive thorough review. It will help reviewers concentrate on key areas that likely have a major impact on the project, resulting in a more effective and efficient review process. \\

\subsubsection{Keyword Selection}
The Keyword Selection technique involves searching for specific keywords that are relevant to the programming languages and frameworks used in the repository. For instance, in a JavaScript or TypeScript project, keywords such as "useState", "useEffect", and "useNavigate" might be targeted. These keywords are associated with important functionalities, such as state management and navigation. Identifying the files that include the selected keywords ensures that the selected files are guaranteed to contain specific functionality and logic. In an educational context, this can be functionality or logic that the course instructor wants to put extra focus on and ensure is included in the PCR. \\

\subsubsection{Cyclomatic Complexity Selection}
Cyclomatic Complexity Selection is a technique that uses the Cyclomatic Complexity metric to measure the complexity of code by quantifying the number of linearly independent paths through the source code. This approach helps identify complex and difficult-to-understand code segments. Targeting these segments for review, this technique aims to select files that help improve the understanding of code maintainability and readability. There are various tools and packages that calculate Cyclomatic Complexity that could be used to automate this process~\cite{Cyclomatic_Complexity}. \\

\subsubsection{Combination Selection}
The Combination Selection technique integrates three different analysis methods to provide a comprehensive selection of the codebase. This technique combines the Halstead measure metric, which is described in the following paragraph, with lines of code, and Cyclomatic Complexity analyses. In addition, there is a final metric called \textit{FTA Score} which is a normalized aggregate of the other metrics that provide an overall indication of maintainability~\cite{FTA_2023}. By using a holistic approach, Combination Selection captures multiple dimensions of the code, ensuring that critical and complex segments are highlighted for in-depth review. This versatile technique helps provide a balanced evaluation of the codebase, addressing various aspects of code quality. This metric can be analyzed using the FTA (Fast TypeScript Analyzer) tool\footnote{https://ftaproject.dev/}.\\

\textbf{Halstead complexity measure} \label{halstead} \\
The Halstead Complexity measures, introduced by Maurice Halstead in 1977, are a set of software metrics used to quantify the complexity of a program based on its source code.~\cite{halstead} These measures are derived from the counts of operators and operands in the code. The primary metrics include the total number of operators and operands, the number of distinct operators and operands, and from these, additional measures such as program length, program vocabulary, volume, difficulty, and effort can be calculated. The volume represents the size of an algorithm's implementation, the difficulty estimates how complex the program is to write and understand, and the effort combines these factors to reflect the mental effort required to develop or maintain the program. The Halstead metrics offer insight into the inherent complexity and potential maintenance difficulties of the code. Unlike Cyclomatic Complexity, which concentrates on the control flow of the program, Halstead Complexity measures the cognitive complexity, referring to the mental effort required to comprehend the code~\cite{Software_Complexity_2021}. \\


% Non-selected selection techniques.
\subsubsection{Code Smell Detection}
Code Smell Detection involves identifying code patterns that might indicate deeper problems, known as "code smells"~\cite{Code_Smells}. These can include duplicated code, dead code, long parameter list, or other indicators of poor design. This technique helps reviewers focus on sections of the code that might require improvements or refactoring by selecting these files for review. \\

\subsubsection{Change Frequency Selection}
Change Frequency Selection is a method that identifies files based on the frequency of changes or commits. Files that are often modified may signal problematic parts of the code that are changing rapidly. This technique ensures that these potentially problematic and unstable areas receive closer inspection by selecting these files for review. \\

\subsubsection{Bug History Selection}
Bug History Selection focuses on files that have a history of bugs and issues. Files that often get bug reports or fixes are likely to contain underlying problems that should be addressed. This technique aims to identify and resolve problematic segments and recurring issues that might help improve the reliability of the code by selecting these files for review. \\

\subsubsection{Dependency Selection} 
Dependency Analysis is a technique that selects files based on their dependency relationships within the codebase. Files that are highly dependent on other parts of the project are critical to the functionality and stability. This technique aims to reduce the risk of large and significant issues and improve the stability of the project by targeting these files for review.