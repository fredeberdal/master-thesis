



@misc{McTighe_Frontier, title={How to Provide Better Feedback Through Rubrics}, url={https://www.ascd.org/el/articles/how-to-provide-better-feedback-through-rubrics}, abstractNote={Well-crafted rubrics create a shared language that lets teachers and students work together.}, journal={ASCD}, author={McTighe, Jay and Frontier, Tony}, language={en} }


@misc{What_is_Structured_Programming?, url={https://www.techtarget.com/searchsoftwarequality/definition/structured-programming-modular-programming}, abstractNote={Learn how structured programming utilizes readable code and reusable components. Understand the components, types, advantages and disadvantages.}, author={Tom Nolle}, journal={Software Quality}, language={en} }

@misc{Software_Complexity_2021, 
title ={Measuring Software Complexity: What Metrics to Use?},
howpublished = {\url{https://thevaluable.dev/complexity-metrics-software/}},
note = {Accessed: 10-04-2024},
abstractNote={Do we need to measure complexity? With what metrics? What benefits can it brings? This is the questions we’ll answer in this article.}, 
journal={The Valuable Dev}, year={2021}, month=nov, language={en-us} }

 @misc{Nations, title={THE 17 GOALS | Sustainable Development}, url={https://sdgs.un.org/goals}, author={Nations, United} }

@misc{SDGs, title={Sustainable Development Goals picture}, url={https://www.un.org/sustainabledevelopment/news/communications-material/}, year={2019}, author={Nations, United} }

@misc{Fordypningsprosjekt, title={From Industry to Academia: 
Integrating Code Review in Education}, year={2023}, author={Berdal, Frede K. and Schjøtt, André},}

 @misc{Code_Smells, 
title ={Code Smells: What Are They And How Can I Prevent Them?},
howpublished = {\url{https://linearb.io/blog/what-is-a-code-smell}},
note = {Accessed: 29-04-2024},
abstractNote={What is a code smell? In this post we will find that out and also discuss prevent them from occurring in the first place.}, 
year={2022}, month=may, language={en} }


 @misc{Cyclomatic_Complexity, 
title ={What is Cyclomatic Complexity?},
howpublished = {\url{https://www.sonarsource.com/learn/cyclomatic-complexity/}},
note = {Accessed: 29-05-2024},
abstractNote={Cyclomatic complexity serves as a vital gauge in computer science, quantifying a program’s complexity by counting its independent paths. Monitoring this metric enables the pinpointing of problematic code sections prone to errors, facilitating easier maintenance and overall robustness in software development.}, 
language={en} }


 @article{Hundhausen_Agrawal_Agarwal_2013, title={Talking about code: Integrating pedagogical code reviews into early computing courses}, volume={13}, DOI={10.1145/2499947.2499951}, abstractNote={Given the increasing importance of soft skills in the computing profession, there is good reason to provide students with more opportunities to learn and practice those skills in undergraduate computing courses. Toward that end, we have developed an active learning approach for computing education called the Pedagogical Code Review (PCR). Inspired by the code inspection process used in the software industry, a PCR is a collaborative activity in which a small team of students, led by a trained moderator: (a) walk through segments of each other’s programming solutions, (b) check the code against a list of best coding practices, and (c) discuss and log issues that arise. To evaluate the viability and effectiveness of this approach, we conducted a series of four mixed-method empirical studies of various implementations of PCRs in CS1 courses at Washington State University. The first study validated the viability of the PCR activity. Using a quasi-experimental design, the final three studies evaluated two alternative implementations of PCRs—face-to-face and online. Our results provide evidence that PCRs can promote positive attitudinal shifts, and hone skills in critical review, teamwork, and communication. Based on our findings, we present a set of best practices for implementing PCRs.}, number={3}, journal={ACM Transactions on Computing Education}, author={Hundhausen, Christopher D. and Agrawal, Anukrati and Agarwal, Pawan}, year={2013}, month=aug, pages={14:1-14:28} }


 @inproceedings{Berkling_Neubehler_2019, title={Boosting Student Performance with Peer Reviews; Integration and Analysis of Peer Reviews in a Gamified Software Engineering Classroom}, ISSN={2165-9567}, url={https://ieeexplore.ieee.org/document/8725247}, DOI={10.1109/EDUCON.2019.8725247}, abstractNote={Peer Reviews between students in higher education is the topic of this paper. By integrating this instruction method into university classroom activities, students train meta-skills and self-reflection, encouraged not only through giving constructive feedback to others but also by reflecting critically on received feedback for their own projects. Methodically, we analyzed over 500 peer reviews in a project-based two semester long Software Engineering class. First, the gamified set-up of the class design is described because the peer review constitutes an integral part thereof. The process of peer reviewing is then reported in detail, including a transcript of an interaction. Finally, we look at the content of peer reviews that are used to improve homework and estimate the number of improvements in the final project hand-in. It can be shown that the peer review contributes in a positive way to students’ learning experience and the quality of their final hand-in.}, booktitle={2019 IEEE Global Engineering Education Conference (EDUCON)}, author={Berkling, Kay and Neubehler, Katja}, year={2019}, month=apr, pages={253–262} }


@book{Design_Science,
author = {Dresch, Aline and Lacerda, Daniel and Antunes Júnior, José Antonio Valle},
year = {2014},
month = {09},
pages = {},
title = {Design Science Research: A Method for Science and Technology Advancement},
isbn = {978-3-319-07373-6},
journal = {Design Science Research: A Method for Science and Technology Advancement},
doi = {10.1007/978-3-319-07374-3}
}

@misc{FTA_2023, 
title ={FTA Project},
howpublished = {\url{https://ftaproject.dev/}},
note = {Accessed: 24-03-2024},
year={2023}, month=may }

@book{halstead,
author = {Halstead, Maurice H.},
title = {Elements of Software Science (Operating and programming systems series)},
year = {1977},
isbn = {0444002057},
publisher = {Elsevier Science Inc.},
address = {USA}
}

 @inproceedings{Ada_Majid_2022, address={Hung Hom, Hong Kong}, title={Developing a system to increase motivation and engagement in student code peer review}, rights={https://doi.org/10.15223/policy-029}, ISBN={978-1-66549-117-4}, url={https://ieeexplore.ieee.org/document/10148331/}, DOI={10.1109/TALE54877.2022.00023}, booktitle={2022 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, publisher={IEEE}, author={Ada, Mireilla Bikanga and Majid, Mohammad U.}, year={2022}, month=dec, pages={93–98} }


 @article{MacLeod_2018, title={Code Reviewing in the Trenches: Challenges and Best Practices}, volume={35}, rights={https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}, ISSN={0740-7459, 1937-4194}, DOI={10.1109/MS.2017.265100500}, number={4}, journal={IEEE Software}, author={MacLeod, Laura and Greiler, Michaela and Storey, Margaret-Anne and Bird, Christian and Czerwonka, Jacek}, year={2018}, month=jul, pages={34–42} }


 @inproceedings{Brown_2019, address={Covington, KY, USA}, title={Using Peer Code Review to Support Pedagogy in an Introductory Computer Programming Course}, rights={https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}, ISBN={978-1-72811-746-1}, url={https://ieeexplore.ieee.org/document/9028509/}, DOI={10.1109/FIE43999.2019.9028509}, booktitle={2019 IEEE Frontiers in Education Conference (FIE)}, publisher={IEEE}, author={Brown, Tamaike and Narasareddygari, Mourya Reddy and Singh, Maninder and Walia, Gursimran}, year={2019}, month=oct, pages={1–7} }


 @misc{Tabnine_2023, 
title ={Code reviews in 2023: Navigating the evolution of software development},
howpublished = {\url{https://www.tabnine.com/blog/code-reviews-in-2023-navigating-the-evolution-of-software-development/}},
note = {Accessed: 20-05-2024},
abstractNote={We’ll delve into the benefits of code reviews, the challenges faced by developers, and ways to make code reviews more efficient in your organization.}, 
journal={Tabnine}, year={2023}, month=feb, language={en-US} }


 @inproceedings{Bacchelli_Bird_2013, title={Expectations, outcomes, and challenges of modern code review}, ISSN={1558-1225}, url={https://ieeexplore.ieee.org/document/6606617}, DOI={10.1109/ICSE.2013.6606617}, abstractNote={Code review is a common software engineering practice employed both in open source and industrial contexts. Review today is less formal and more “lightweight” than the code inspections performed and studied in the 70s and 80s. We empirically explore the motivations, challenges, and outcomes of tool-based code reviews. We observed, interviewed, and surveyed developers and managers and manually classified hundreds of review comments across diverse teams at Microsoft. Our study reveals that while finding defects remains the main motivation for review, reviews are less about defects than expected and instead provide additional benefits such as knowledge transfer, increased team awareness, and creation of alternative solutions to problems. Moreover, we find that code and change understanding is the key aspect of code reviewing and that developers employ a wide range of mechanisms to meet their understanding needs, most of which are not met by current tools. We provide recommendations for practitioners and researchers.}, booktitle={2013 35th International Conference on Software Engineering (ICSE)}, author={Bacchelli, Alberto and Bird, Christian}, year={2013}, month=may, pages={712–721} }


 @misc{Agile_Code_Review, 
title ={Code Review: An Agile Process},
howpublished = {\url{https://smartbear.com/learn/code-review/agile-code-review-process/}},
note = {Accessed: 20-05-2024},
abstractNote={Contrary to what many believe, the benefits of code review closely align to the tenets outlined in the Agile Manifesto. Statistics prove that peer code review is one of the most effective ways to improve software quality by reducing defects upstream. By aligning a peer code review approach with y...}, 
journal={smartbear.com} }


 @inproceedings{Song_Goldstein_Sakr_2020, address={New York, NY, USA}, series={ITiCSE ’20}, title={Using Peer Code Review as an Educational Tool}, ISBN={978-1-4503-6874-2}, url={https://dl.acm.org/doi/10.1145/3341525.3387370}, DOI={10.1145/3341525.3387370}, abstractNote={Code-review, the systematic examination of source code, is widely used in industry, but seldom used in courses. We designed and implemented a rubric-driven online peer code-review system (PCR) that we have deployed for two semesters, during which 228 students performed over 1003 code reviews. PCR is designed to meet four goals: (1) Provide timely feedback to students on their submissions, (2) Teach students the art of code review, (3) Allow custom feedback on submissions even in massive online classes, and (4) Allow students to learn from each other. We report on using PCR, in particular, the accuracy of student-based reviews, the surprising number of free-form comments made by students, the variability of staff-based reviews, how student engagement impacts the accuracy, the additional workload, and anecdotal perspectives of students. We describe some critical design considerations for PCR including rubric design, the importance of PCR training on each assignment to acclimate students to the rubric, and how we match student reviewers to student submissions.}, booktitle={Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education}, publisher={Association for Computing Machinery}, author={Song, Xiangyu and Goldstein, Seth Copen and Sakr, Majd}, year={2020}, month=jun, pages={173–179}, collection={ITiCSE ’20} }


 @article{Aalberg_Lorås_2018, title={Active learning and student peer assessment in a web development course}, ISSN={1892-0713}, url={https://ntnuopen.ntnu.no/ntnu-xmlui/handle/11250/2582857}, abstractNote={Active learning is a family of instructional practises that requires students to participate in learning activities and engages students in the learning process. For larger groups, however, this it is often challenging to implement. Peer assessment, where students or groups of students evaluate and give feedback to each other, complements many traditional learning activities very well and combined this is promising active learning method that potentially is independent of the cohort size. In this paper, we present an active learning approach that is implemented in a web development course at the Norwegian University of Science and Technology where we combine project based activities and use peer assessment to engage students in the learning. Reference group meetings and the annual survey at the department is used for evaluating the peer assessment method, and we present an analysis comparing the scores given by fellow students with the grades given by faculty for the exam. Our findings include the observation that students are willing to put a lot of effort into activities they know count towards a grade, including peer assessments. However, when assessing each other they tend to give scores in the high range, which makes it hard to differentiate between students. Students also tend to believe that the assessments they get from other students are less reliable and fair, although the analysis shows that the scores they get in the peer assessments of projects corresponds with the evaluation given by the teacher for the exam.}, note={Accepted: 2019-01-29T13:22:25Z}, journal={NIK: Norsk Informatikkonferanse}, publisher={Bibsys Open Journal Systems}, author={Aalberg, Trond and Lorås, Madeleine}, year={2018}, language={eng} }


@inproceedings{Rigby_Bird_2013, address={New York, NY, USA}, series={ESEC/FSE 2013}, title={Convergent contemporary software peer review practices}, ISBN={978-1-4503-2237-9}, url={https://dl.acm.org/doi/10.1145/2491411.2491444}, DOI={10.1145/2491411.2491444}, abstractNote={Software peer review is practiced on a diverse set of software projects that have drastically different settings, cultures, incentive systems, and time pressures. In an effort to characterize and understand these differences we examine two Google-led projects, Android and Chromium OS, three Microsoft projects, Bing, Office, and MS SQL, and projects internal to AMD. We contrast our findings with data taken from traditional software inspection conducted on a Lucent project and from open source software peer review on six projects, including Apache, Linux, and KDE. Our measures of interest include the review interval, the number of developers involved in review, and proxy measures for the number of defects found during review. We find that despite differences among projects, many of the characteristics of the review process have independently converged to similar values which we think indicate general principles of code review practice. We also introduce a measure of the degree to which knowledge is shared during review. This is an aspect of review practice that has traditionally only had experiential support. Our knowledge sharing measure shows that conducting peer review increases the number of distinct files a developer knows about by 66% to 150% depending on the project. This paper is one of the first studies of contemporary review in software firms and the most diverse study of peer review to date.}, booktitle={Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering}, publisher={Association for Computing Machinery}, author={Rigby, Peter C. and Bird, Christian}, year={2013}, month=aug, pages={202–212}, collection={ESEC/FSE 2013} }


 @inproceedings{Bosu_Microsoft, title={Characteristics of Useful Code Reviews: An Empirical Study at Microsoft}, ISSN={2160-1860}, url={https://ieeexplore.ieee.org/document/7180075}, DOI={10.1109/MSR.2015.21}, abstractNote={Over the past decade, both open source and commercial software projects have adopted contemporary peer code review practices as a quality control mechanism. Prior research has shown that developers spend a large amount of time and effort performing code reviews. Therefore, identifying factors that lead to useful code reviews can benefit projects by increasing code review effectiveness and quality. In a three-stage mixed research study, we qualitatively investigated what aspects of code reviews make them useful to developers, used our findings to build and verify a classification model that can distinguish between useful and not useful code review feedback, and finally we used this classifier to classify review comments enabling us to empirically investigate factors that lead to more effective code review feedback. In total, we analyzed 1.5 millions review comments from five Microsoft projects and uncovered many factors that affect the usefulness of review feedback. For example, we found that the proportion of useful comments made by a reviewer increases dramatically in the first year that he or she is at Microsoft but tends to plateau afterwards. In contrast, we found that the more files that are in a change, the lower the proportion of comments in the code review that will be of value to the author of the change. Based on our findings, we provide recommendations for practitioners to improve effectiveness of code reviews.}, booktitle={2015 IEEE/ACM 12th Working Conference on Mining Software Repositories}, author={Bosu, Amiangshu and Greiler, Michaela and Bird, Christian}, year={2015}, month=may, pages={146–156} }




 @inproceedings{Fregnan_2022, address={New York, NY, USA}, series={ESEC/FSE 2022}, title={First come first served: the impact of file position on code review}, ISBN={978-1-4503-9413-0}, url={https://dl.acm.org/doi/10.1145/3540250.3549177}, DOI={10.1145/3540250.3549177}, abstractNote={The most popular code review tools (e.g., Gerrit and GitHub) present the files to review sorted in alphabetical order. Could this choice or, more generally, the relative position in which a file is presented bias the outcome of code reviews? We investigate this hypothesis by triangulating complementary evidence in a two-step study. First, we observe developers’ code review activity. We analyze the review comments pertaining to 219,476 Pull Requests (PRs) from 138 popular Java projects on GitHub. We found files shown earlier in a PR to receive more comments than files shown later, also when controlling for possible confounding factors: e.g., the presence of discussion threads or the lines added in a file. Second, we measure the impact of file position on defect finding in code review. Recruit- ing 106 participants, we conduct an online controlled experiment in which we measure participants’ performance in detecting two unrelated defects seeded into two different files. Participants are assigned to one of two treatments in which the position of the defective files is switched. For one type of defect, participants are not affected by its file’s position; for the other, they have 64% lower odds to identify it when its file is last as opposed to first. Overall, our findings provide evidence that the relative position in which files are presented has an impact on code reviews’ outcome; we discuss these results and implications for tool design and code review.}, booktitle={Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering}, publisher={Association for Computing Machinery}, author={Fregnan, Enrico and Braz, Larissa and D’Ambros, Marco and Çalıklı, Gül and Bacchelli, Alberto}, year={2022}, month=nov, pages={483–494}, collection={ESEC/FSE 2022} }


 @inproceedings{Bagirov_2023, address={New York, NY, USA}, series={EASE ’23}, title={Assessing the Impact of File Ordering Strategies on Code Review Process}, ISBN={9798400700446}, url={https://dl.acm.org/doi/10.1145/3593434.3593462}, DOI={10.1145/3593434.3593462}, abstractNote={Popular modern code review tools (e.g., Gerrit and GitHub) sort files in a code review in alphabetical order. A prior study (on open-source projects) shows that the changed files’ positions in the code review affect the review process. Their results show that files placed lower in the order have less chance of receiving reviewing efforts than the other files. Hence, there is a higher chance of missing defects in these files. This paper explores the impact of file order in the code review of the well-known industrial project IntelliJ IDEA. First, we verify the results of the prior study on a big proprietary software project. Then, we explore an alternative to the default Alphabetical order: ordering changed files according to their code diff. Our results confirm the observations of the previous study. We discover that reviewers leave more comments on the files shown higher in the code review. Moreover, these results show that, even with the data skewed toward Alphabetical order, ordering changed files according to their code diff performs better than standard Alphabetical order regarding placing problematic files, which needs more reviewing effort, in the code review. These results confirm that exploring various ordering strategies for code review needs more exploration.}, booktitle={Proceedings of the 27th International Conference on Evaluation and Assessment in Software Engineering}, publisher={Association for Computing Machinery}, author={Bagirov, Farid and Derakhshanfar, Pouria and Kalina, Alexey and Kartysheva, Elena and Kovalenko, Vladimir}, year={2023}, month=jun, pages={188–191}, collection={EASE ’23} }


 @article{Indriasari_Luxton_2020, title={A Review of Peer Code Review in Higher Education}, volume={20}, DOI={10.1145/3403935}, abstractNote={Peer review is the standard process within academia for maintaining publication quality, but it is also widely employed in other settings, such as education and industry, for improving work quality and for generating actionable feedback to content authors. For example, in the software industry peer review of program source code—or peer code review—is a key technique for detecting bugs and maintaining coding standards. In a programming education context, although peer code review offers potential benefits to both code reviewers and code authors, individuals are typically less experienced, which presents a number of challenges. Some of these challenges are similar to those reported in the educational literature on peer review in other academic disciplines, but reviewing code presents unique difficulties. Better understanding these challenges and the conditions under which code review can be taught and implemented successfully in computer science courses is of value to the computing education community. In this work, we conduct a systematic review of the literature on peer code review in higher education to examine instructor motivations for conducting peer code review activities, how such activities have been implemented in practice, and the primary benefits and difficulties that have been reported. We initially identified 187 potential studies and analyzed 51 empirical studies pertinent to our goals. We report the most commonly cited benefits (e.g., the development of programming-related skills) and barriers (e.g., low student engagement), and we identify a wide variety of tools that have been used to facilitate the peer code review process. While we argue that more empirical work is needed to validate currently reported results related to learning outcomes, there is also a clear need to address the challenges around student motivation, which we believe could be an important avenue for future research.}, number={3}, journal={ACM Transactions on Computing Education}, author={Indriasari, Theresia Devi and Luxton-Reilly, Andrew and Denny, Paul}, year={2020}, month=sep, pages={22:1-22:25} }


 @book{Wang_evolution, title={The Evolution of Code Review Research: A Systematic Mapping Study}, abstractNote={Code Review (CR) is a cornerstone for Quality Assurance within software development teams. Also known as “software inspections” and “walk-throughs”, traditional CR involved time-consuming processes, which is different from more lightweight contemporary forms used today. In this paper, we aim to summarize how CR research has evolved into its current state over the last decade. Our vigorous systematic study revolves around four research questions to uncover changes into the target of contributions and methodologies, replicability of existing studies and the evolution of CR terminology. From a collection of 7,266 papers from the top software engineering venues, we generate visual maps for 148 collected papers including 53 conferences, 16 journals, and 79 snowball papers. Our visual maps provide evidence that CR research does cover more than quality assurance, and will continue to evolve with the availability of datasets and emerging technologies within the CR domain.}, author={Wang, Dong and Ueda, Yuki and Kula, Raula and Ishio, Takashi and Matsumoto, Kenichi}, year={2019}, month=nov }


 @inproceedings{sadowski_google, 
address={New York, NY, USA}, 
series={ICSE-SEIP ’18}, 
title={Modern code review: a case study at google}, 
ISBN={978-1-4503-5659-6}, 
url={https://dl.acm.org/doi/10.1145/3183519.3183525}, 
DOI={10.1145/3183519.3183525}, 
abstractNote={Employing lightweight, tool-based code review of code changes (aka modern code review) has become the norm for a wide variety of open-source and industrial systems. In this paper, we make an exploratory investigation of modern code review at Google. Google introduced code review early on and evolved it over the years; our study sheds light on why Google introduced this practice and analyzes its current status, after the process has been refined through decades of code changes and millions of code reviews. By means of 12 interviews, a survey with 44 respondents, and the analysis of review logs for 9 million reviewed changes, we investigate motivations behind code review at Google, current practices, and developers’ satisfaction and challenges.}, 
booktitle={Proceedings of the 40th International Conference on Software Engineering: Software Engineering in Practice}, 
publisher={Association for Computing Machinery}, 
author={Sadowski, Caitlin and Söderberg, Emma and Church, Luke and Sipko, Michal and Bacchelli, Alberto}, 
year={2018}, 
month=may, 
pages={181–190}, 
collection={ICSE-SEIP ’18} }


@article{Fagan, 
title={Design and code inspections to reduce errors in program development}, 
volume={15}, 
ISSN={0018-8670}, 
DOI={10.1147/sj.153.0182}, 
abstractNote={We can summarize the discussion of design and code inspections and process control in developing programs as follows: 1. Describe the program development process in terms of operations, and define exit criteria which must be satisfied for completion of each operation. 2. Separate the objectives of the inspection process operations to keep the inspection team focused on one objective at a time: Operation Overview Preparation Inspection Rework Follow-up Objective Communications/education Education Find errors Fix errors Ensure all fixes are applied correctly 3. Classify errors by type, and rank frequency of occurrence of types. Identify which types to spend most time looking for in the inspection. 4. Describe how to look for presence of error types. 5. Analyze inspection results and use for constant process improvement (until process averages are reached and then use for process control).}, 
number={3}, 
journal={IBM Systems Journal}, 
author={Fagan, M. E.}, 
year={1976}, 
pages={182–211} }


@INPROCEEDINGS{Expectations_outcomes,
  author={Bacchelli, Alberto and Bird, Christian},
  booktitle={2013 35th International Conference on Software Engineering (ICSE)}, 
  title={Expectations, outcomes, and challenges of modern code review}, 
  year={2013},
  volume={},
  number={},
  pages={712-721},
  keywords={Interviews;Inspection;Software;Context;Sorting;Guidelines;Knowledge transfer},
  doi={10.1109/ICSE.2013.6606617}}

 @misc{
gitlab_What_is_a_code_review?,  
title={What is Code Review},
howpublished = {\url{https://about.gitlab.com/topics/version-control/what-is-code-review/}},
note = {Accessed: 14-03-2024},
journal={Gitlab},
abstractNote={Code reviews ensure developers ship the highest quality code through systematic assessments designed to identify bugs.}, 
language={en-us} }


 @misc{atlassian_What_is_a_code_review, 
title={What is a Code Review \& How It Can Save Time}, 
url={https://www.atlassian.com/agile/software-development/code-reviews}, 
abstractNote={Code review helps developers learn the code base, as well as help them learn new technologies and techniques that grow their skill sets. Learn more here.}, 
journal={Atlassian}, 
author={Dan, Radigan}, 
language={en} }